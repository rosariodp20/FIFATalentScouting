{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROGETTO FINALE\n",
    "\n",
    "## FIFA Talent Scouting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importo le librerie necessarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import learning_curve, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carico il file nel DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giocatori = pd.read_csv(\"players_20.csv\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visiono il DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opzione che mi permette di mostrare tutte le colonne del csv\n",
    "pd.set_option('display.max_columns', None)   #None mi fa vedere tutte le colonne, se metto un numero N mi\n",
    "#fa vedere N colonne\n",
    "\n",
    "#stampo la parte iniziale del file per poterne visionare le caratteristiche\n",
    "print(giocatori.shape)\n",
    "giocatori.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inizio processo di EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Andiamo a considerare solo le features più importanti per lo scouting\n",
    "\n",
    "giocatori=giocatori[[\"age\",\"overall\",\"potential\",\"value_eur\",\"wage_eur\",\"weak_foot\",\"skill_moves\"]]\n",
    "\n",
    "#Voglio tenere solo i giocatori al di sotto di una certa età e un certo overall per effettuare lo scouting\n",
    "\n",
    "giocatori = giocatori.drop(giocatori[giocatori.age>25].index)\n",
    "giocatori = giocatori.drop(giocatori[giocatori.overall>75].index)\n",
    "#giocatori = giocatori.drop(giocatori[giocatori.age<18].index)\n",
    "#giocatori = giocatori.drop(giocatori[giocatori.overall<52].index)\n",
    "\n",
    "print(giocatori.shape)\n",
    "giocatori.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vediamo se abbiamo valori nulli o non definiti\n",
    "giocatori.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(giocatori.groupby([\"age\"]).size())\n",
    "print()\n",
    "giocatori.groupby([\"overall\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Andiamo a vedere quali sono le features che influenzano di più la nostra classe, che ricordiamo essere \"Potential\"\n",
    "\n",
    "correlation=giocatori.corr()\n",
    "\n",
    "a4_dims = (10, 7)\n",
    "fig, ax = plt.subplots(figsize=a4_dims)\n",
    "\n",
    "sns.heatmap(data=correlation, square=True, cmap='YlOrRd', ax=ax, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = giocatori.drop('potential',1)\n",
    "#y = giocatori.potential\n",
    "\n",
    "#x.shape, y.shape\n",
    "\n",
    "x=np.array(giocatori.drop(['potential'],1))\n",
    "y=np.array(giocatori['potential'])\n",
    "\n",
    "#Senza lo Scaler l'algoritmo SGD non funziona\n",
    "scaler = preprocessing.StandardScaler().fit(x)\n",
    "x = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.3, random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creo il modello per la Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Richiamo l'algoritmo LinearRegression e creo il modello sul dataset di train\n",
    "linreg=LinearRegression()\n",
    "linreg.fit(x_train, y_train)\n",
    "\n",
    "#Valutiamo l'accuratezza del modello di regressione sul dataset di train e di test\n",
    "accuracy_train=linreg.score(x_train, y_train)\n",
    "accuracy_test=linreg.score(x_test,y_test)  \n",
    "print(\"L'accuratezza per il dataset di train con splitting è:\", accuracy_train)\n",
    "print(\"L'accuratezza per il dataset di test con splitting è:\", accuracy_test)\n",
    "\n",
    "#Andiamo a vedere l'accuratezza inserendo una cross-validation al posto dello splitting, per evitare l'overfitting\n",
    "#score=cross_val_score(linreg, x, y, cv=10, scoring=\"r2\")\n",
    "#print(\"L'accuratezza per il dataset intero con cross-validation è\", score.mean())\n",
    "\n",
    "mse_train=mean_squared_error(y_train, linreg.predict(x_train))   \n",
    "mse_test=mean_squared_error(y_test, linreg.predict(x_test))\n",
    "print(\"The mean squared error (MSE) on train set: {:.4f}\".format(mse_train))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse_test))\n",
    "\n",
    "#score_MSE=cross_val_score(linreg, x, y, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "#print(\"Il MSE per il dataset intero con cross-validation è\", -score_MSE.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creo il modello per la Rete Neurale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo il modello con l'algoritmo rete neurale\n",
    "\n",
    "MLP=MLPRegressor(tol=0.00005, max_iter=1000, hidden_layer_sizes=10)\n",
    "MLP.fit(x_train, y_train)\n",
    "\n",
    "#Valutiamo l'accuratezza del modello di regressione sul dataset di train e di test\n",
    "accuracy_train=MLP.score(x_train, y_train)\n",
    "accuracy_test=MLP.score(x_test,y_test)  \n",
    "print(\"L'accuratezza per il dataset di train con splitting è:\", accuracy_train)\n",
    "print(\"L'accuratezza per il dataset di test con splitting è:\", accuracy_test)\n",
    "\n",
    "#Andiamo a vedere l'accuratezza inserendo una cross-validation al posto dello splitting, per evitare l'overfitting\n",
    "#score=cross_val_score(MLP, x, y, cv=10, scoring=\"r2\")\n",
    "#print(\"L'accuratezza per il dataset intero con cross-validation è\", score.mean())\n",
    "\n",
    "mse_train=mean_squared_error(y_train, MLP.predict(x_train))   \n",
    "mse_test=mean_squared_error(y_test, MLP.predict(x_test))\n",
    "print(\"The mean squared error (MSE) on train set: {:.4f}\".format(mse_train))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse_test))\n",
    "\n",
    "\n",
    "#score_MSE=cross_val_score(MLP, x, y, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "#print(\"Il MSE per il dataset intero con cross-validation è\", -score_MSE.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizziamo le learning curves\n",
    "\n",
    "_sizes=[i for i in range(1, 4600,10)]\n",
    "train_sizes=np.array(_sizes)  # Relative sizes\n",
    "scoring='neg_mean_squared_error'\n",
    "\n",
    "lr=LinearRegression()\n",
    "\n",
    "train_sizes_abs, train_scores, validation_scores = learning_curve(\n",
    "    lr, x_train, y_train, train_sizes=train_sizes, cv=10, scoring=scoring, shuffle=True)\n",
    "\n",
    "\n",
    "train_scores_mean = -train_scores.mean(axis = 1)\n",
    "validation_scores_mean = -validation_scores.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plottiamo le learning curves\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(train_sizes_abs, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes_abs, validation_scores_mean, label = 'Cross-Validation error')\n",
    "plt.ylabel('MSE', fontsize = 14)\n",
    "plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)\n",
    "plt.legend()\n",
    "plt.ylim(0,10)\n",
    "plt.xlim(0,400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creo il modello per il Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giocatori.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giocatori[\"potential_dis\"]=\"\"\n",
    "numeroRighe= giocatori.shape[0] \n",
    "for i in range(0,numeroRighe):\n",
    "    if giocatori.iat[i,2]-giocatori.iat[i,1] > 10:\n",
    "        giocatori.iat[i,7]=\"Ottima crescita >10\"\n",
    "    elif giocatori.iat[i,2]-giocatori.iat[i,1] > 7 and giocatori.iat[i,2]-giocatori.iat[i,1] <= 10:\n",
    "        giocatori.iat[i,7]=\"Buona crescita ]7,10]\"\n",
    "    elif giocatori.iat[i,2]-giocatori.iat[i,1] > 3 and giocatori.iat[i,2]-giocatori.iat[i,1] <= 7:\n",
    "        giocatori.iat[i,7]=\"Normale crescita ]3,7]\" \n",
    "    elif giocatori.iat[i,2]-giocatori.iat[i,1] <= 3:\n",
    "        giocatori.iat[i,7]=\"Pessima crescita <=3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giocatori = giocatori[[ \"age\",\"overall\",\"value_eur\",\"wage_eur\",\"weak_foot\",\"skill_moves\",\"potential_dis\"]]\n",
    "giocatori.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = giocatori.drop('potential_dis',axis=1)\n",
    "y = giocatori['potential_dis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestClassifier(n_estimators=20, random_state=1)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvataggio Modelli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salviamo i modelli di machine learning\n",
    "\n",
    "#Modello regressione lineare\n",
    "filename = 'FifaModelLinReg.sav'    \n",
    "pickle.dump(linreg, open(filename, 'wb'))\n",
    "\n",
    "#Modello rete neurale\n",
    "filename = 'FifaModelMLP.sav'    \n",
    "pickle.dump(MLP, open(filename, 'wb'))\n",
    "\n",
    "#Modello random forest classifier\n",
    "filename = 'FifaModelRanForClas.sav'    \n",
    "pickle.dump(regressor, open(filename, 'wb'))\n",
    "\n",
    "\n",
    "\n",
    "################################## CODICE PER CARICARE I MODELLI #########################################\n",
    "\n",
    "# Carico il modello di regressione lineare precedentemente salvato\n",
    "#loaded_model = pickle.load(open('FifaModelLinReg.sav', 'rb'))\n",
    "#result = loaded_model.score(x, y)\n",
    "#print(result)\n",
    "\n",
    "#Carico il modello di rete neurale precedentemente salvato\n",
    "#loaded_model = pickle.load(open('FifaModelMLP.sav', 'rb'))\n",
    "#result = loaded_model.score(x, y)\n",
    "#print(result)\n",
    "\n",
    "#Carico il modello di rete neurale precedentemente salvato\n",
    "#loaded_model = pickle.load(open('FifaModelRanForClas.sav', 'rb'))\n",
    "#result = loaded_model.score(x, y)\n",
    "#print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
